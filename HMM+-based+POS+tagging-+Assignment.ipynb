{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using modified Viterbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "#Importing libraries\n",
    "import nltk, re, pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Treebank tagged sentences\n",
    "nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3718\n",
      "196\n",
      "[[('In', 'ADP'), ('composite', 'ADJ'), ('trading', 'NOUN'), ('on', 'ADP'), ('the', 'DET'), ('New', 'NOUN'), ('York', 'NOUN'), ('Stock', 'NOUN'), ('Exchange', 'NOUN'), (',', '.'), ('Telerate', 'NOUN'), ('shares', 'NOUN'), ('closed', 'VERB'), ('at', 'ADP'), ('$', '.'), ('19.50', 'NUM'), ('*U*', 'X'), (',', '.'), ('up', 'ADV'), ('12.5', 'NUM'), ('cents', 'NOUN'), ('.', '.')], [('``', '.'), ('Professional', 'ADJ'), ('sugar', 'NOUN'), ('people', 'NOUN'), ('here', 'ADV'), ('who', 'PRON'), ('*T*-1', 'X'), ('have', 'VERB'), ('strong', 'ADJ'), ('contacts', 'NOUN'), ('with', 'ADP'), ('the', 'DET'), ('Brazilian', 'ADJ'), ('sugar', 'NOUN'), ('industry', 'NOUN'), ('have', 'VERB'), ('been', 'VERB'), ('unable', 'ADJ'), ('*-3', 'X'), ('to', 'PRT'), ('confirm', 'VERB'), ('the', 'DET'), ('reports', 'NOUN'), ('or', 'CONJ'), ('get', 'VERB'), ('enough', 'ADJ'), ('information', 'NOUN'), ('0', 'X'), ('*', 'X'), ('to', 'PRT'), ('clarify', 'VERB'), ('the', 'DET'), ('situation', 'NOUN'), ('*T*-4', 'X'), (',', '.'), (\"''\", '.'), ('he', 'PRON'), ('said', 'VERB'), ('*T*-2', 'X'), ('.', '.')], [('Newsweek', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('will', 'VERB'), ('introduce', 'VERB'), ('the', 'DET'), ('Circulation', 'NOUN'), ('Credit', 'NOUN'), ('Plan', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('awards', 'VERB'), ('space', 'NOUN'), ('credits', 'NOUN'), ('*ICH*-2', 'X'), ('to', 'PRT'), ('advertisers', 'NOUN'), ('on', 'ADP'), ('``', '.'), ('renewal', 'NOUN'), ('advertising', 'NOUN'), ('.', '.'), (\"''\", '.')], [('So', 'ADV'), ('would', 'VERB'), ('*?*', 'X'), ('*T*-1', 'X'), ('the', 'DET'), ('Little', 'NOUN'), ('Tramp', 'NOUN'), (',', '.'), ('for', 'ADP'), ('that', 'DET'), ('matter', 'NOUN'), ('.', '.')], [('Mrs.', 'NOUN'), ('Yeargin', 'NOUN'), ('was', 'VERB'), ('fired', 'VERB'), ('*-1', 'X'), ('and', 'CONJ'), ('prosecuted', 'VERB'), ('*-1', 'X'), ('under', 'ADP'), ('an', 'DET'), ('unusual', 'ADJ'), ('South', 'NOUN'), ('Carolina', 'NOUN'), ('law', 'NOUN'), ('that', 'DET'), ('*T*-79', 'X'), ('makes', 'VERB'), ('it', 'PRON'), ('*EXP*-2', 'X'), ('a', 'DET'), ('crime', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('breach', 'VERB'), ('test', 'NOUN'), ('security', 'NOUN'), ('.', '.')], [('*-1', 'X'), ('Asked', 'VERB'), ('*-2', 'X'), ('whether', 'ADP'), ('potential', 'ADJ'), ('advertisers', 'NOUN'), ('will', 'VERB'), ('be', 'VERB'), ('scared', 'VERB'), ('*-83', 'X'), ('away', 'ADV'), ('by', 'ADP'), ('the', 'DET'), ('magazine', 'NOUN'), (\"'s\", 'PRT'), ('direct', 'ADJ'), ('policy', 'NOUN'), (',', '.'), ('Ms.', 'NOUN'), ('Poore', 'NOUN'), ('replies', 'VERB'), (':', '.'), ('``', '.'), ('I', 'PRON'), ('do', 'VERB'), (\"n't\", 'ADV'), ('know', 'VERB'), ('and', 'CONJ'), ('I', 'PRON'), ('do', 'VERB'), (\"n't\", 'ADV'), ('care', 'VERB'), ('.', '.')], [('The', 'DET'), ('monthly', 'ADJ'), ('sales', 'NOUN'), ('have', 'VERB'), ('been', 'VERB'), ('setting', 'VERB'), ('records', 'NOUN'), ('every', 'DET'), ('month', 'NOUN'), ('since', 'ADP'), ('March', 'NOUN'), ('.', '.')], [('Andrew', 'NOUN'), ('Derel', 'NOUN'), ('Adams', 'NOUN'), (',', '.'), ('Killeen', 'NOUN'), (',', '.'), ('Texas', 'NOUN'), (',', '.'), ('fined', 'VERB'), ('*-1', 'X'), ('$', '.'), ('15,000', 'NUM'), ('*U*', 'X'), (';', '.'), ('John', 'NOUN'), ('Francis', 'NOUN'), ('Angier', 'NOUN'), ('Jr.', 'NOUN'), (',', '.'), ('Reddington', 'NOUN'), ('Shores', 'NOUN'), (',', '.'), ('Fla.', 'NOUN'), (',', '.'), ('$', '.'), ('15,000', 'NUM'), ('*U*', 'X'), (';', '.'), ('Mark', 'NOUN'), ('Anthony', 'NOUN'), (',', '.'), ('Arlington', 'NOUN'), ('Heights', 'NOUN'), (',', '.'), ('Ill.', 'NOUN'), (',', '.'), ('$', '.'), ('10,000', 'NUM'), ('*U*', 'X'), ('and', 'CONJ'), ('30-day', 'ADJ'), ('suspension', 'NOUN'), (';', '.'), ('William', 'NOUN'), ('Stirlen', 'NOUN'), (',', '.'), ('Arlington', 'NOUN'), ('Heights', 'NOUN'), (',', '.'), ('Ill.', 'NOUN'), (',', '.'), ('$', '.'), ('7,500', 'NUM'), ('*U*', 'X'), ('and', 'CONJ'), ('30-day', 'ADJ'), ('suspension', 'NOUN'), (';', '.'), ('Fred', 'NOUN'), ('W.', 'NOUN'), ('Bonnell', 'NOUN'), (',', '.'), ('Boulder', 'NOUN'), (',', '.'), ('Colo.', 'NOUN'), (',', '.'), ('$', '.'), ('2,500', 'NUM'), ('*U*', 'X'), ('and', 'CONJ'), ('six-month', 'ADJ'), ('suspension', 'NOUN'), (';', '.'), ('Michael', 'NOUN'), ('J.', 'NOUN'), ('Boorse', 'NOUN'), (',', '.'), ('Horsham', 'NOUN'), (',', '.'), ('Pa.', 'NOUN'), (';', '.'), ('David', 'NOUN'), ('Chiodo', 'NOUN'), (',', '.'), ('Dallas', 'NOUN'), (',', '.'), ('$', '.'), ('5,000', 'NUM'), ('*U*', 'X'), (',', '.'), ('barred', 'VERB'), ('*-3', 'X'), ('as', 'ADP'), ('a', 'DET'), ('principal', 'NOUN'), (';', '.'), ('Camille', 'NOUN'), ('Chafic', 'NOUN'), ('Cotran', 'NOUN'), (',', '.'), ('London', 'NOUN'), (',', '.'), ('$', '.'), ('25,000', 'NUM'), ('*U*', 'X'), (';', '.'), ('John', 'NOUN'), ('William', 'NOUN'), ('Curry', 'NOUN'), (',', '.'), ('fined', 'VERB'), ('*-4', 'X'), ('$', '.'), ('5,000', 'NUM'), ('*U*', 'X'), (',', '.'), ('ordered', 'VERB'), ('*-4', 'X'), ('*-2', 'X'), ('to', 'PRT'), ('disgorge', 'VERB'), ('$', '.'), ('30,000', 'NUM'), ('*U*', 'X'), (',', '.'), ('one-year', 'ADJ'), ('suspension', 'NOUN'), ('.', '.')], [('No', 'DET'), ('matter', 'NOUN'), ('who', 'PRON'), ('*T*-16', 'X'), ('owns', 'VERB'), ('PS', 'NOUN'), ('of', 'ADP'), ('New', 'NOUN'), ('Hampshire', 'NOUN'), (',', '.'), ('after', 'ADP'), ('it', 'PRON'), ('emerges', 'VERB'), ('from', 'ADP'), ('bankruptcy', 'NOUN'), ('proceedings', 'NOUN'), ('its', 'PRON'), ('rates', 'NOUN'), ('will', 'VERB'), ('be', 'VERB'), ('among', 'ADP'), ('the', 'DET'), ('highest', 'ADJ'), ('in', 'ADP'), ('the', 'DET'), ('nation', 'NOUN'), (',', '.'), ('he', 'PRON'), ('said', 'VERB'), ('0', 'X'), ('*T*-1', 'X'), ('.', '.')], [('Douglas', 'NOUN'), ('Madison', 'NOUN'), (',', '.'), ('a', 'DET'), ('corporate', 'ADJ'), ('trader', 'NOUN'), ('with', 'ADP'), ('Bank', 'NOUN'), ('of', 'ADP'), ('America', 'NOUN'), ('in', 'ADP'), ('Los', 'NOUN'), ('Angeles', 'NOUN'), (',', '.'), ('traced', 'VERB'), ('the', 'DET'), ('dollar', 'NOUN'), (\"'s\", 'PRT'), ('recent', 'ADJ'), ('solid', 'ADJ'), ('performance', 'NOUN'), ('against', 'ADP'), ('the', 'DET'), ('yen', 'NOUN'), ('to', 'PRT'), ('purchases', 'NOUN'), ('of', 'ADP'), ('securities', 'NOUN'), ('by', 'ADP'), ('Japanese', 'ADJ'), ('insurance', 'NOUN'), ('companies', 'NOUN'), ('and', 'CONJ'), ('trust', 'NOUN'), ('banks', 'NOUN'), ('and', 'CONJ'), ('the', 'DET'), ('sense', 'NOUN'), ('that', 'ADP'), ('another', 'DET'), ('wave', 'NOUN'), ('of', 'ADP'), ('investment', 'NOUN'), ('is', 'VERB'), ('waiting', 'VERB'), ('in', 'ADP'), ('the', 'DET'), ('wings', 'NOUN'), ('.', '.')], [('You', 'PRON'), ('look', 'VERB'), ('around', 'PRT'), ('at', 'ADP'), ('professional', 'ADJ'), ('ballplayers', 'NOUN'), ('or', 'CONJ'), ('accountants', 'NOUN'), ('...', '.'), ('and', 'CONJ'), ('nobody', 'NOUN'), ('blinks', 'VERB'), ('an', 'DET'), ('eye', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Baum', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('he', 'PRON'), ('and', 'CONJ'), ('Mr.', 'NOUN'), ('Harper', 'NOUN'), ('both', 'DET'), ('advocated', 'VERB'), ('*-1', 'X'), ('closing', 'VERB'), ('some', 'DET'), ('plants', 'NOUN'), ('as', 'ADV'), ('long', 'ADJ'), ('ago', 'ADV'), ('as', 'ADP'), ('early', 'ADJ'), ('1988', 'NUM'), ('.', '.')], [('But', 'CONJ'), ('Dr.', 'NOUN'), ('Genel', 'NOUN'), ('warns', 'VERB'), ('that', 'ADP'), ('Dr.', 'NOUN'), ('Mason', 'NOUN'), (\"'s\", 'PRT'), ('ruling', 'NOUN'), ('may', 'VERB'), ('discourage', 'VERB'), ('private', 'ADJ'), ('funding', 'NOUN'), ('.', '.')], [('How', 'ADV'), ('many', 'ADJ'), ('government', 'NOUN'), ('programs', 'NOUN'), ('and', 'CONJ'), ('policies', 'NOUN'), ('*T*-1', 'X'), ('exist', 'VERB'), ('because', 'ADP'), ('they', 'PRON'), ('line', 'VERB'), ('the', 'DET'), ('pockets', 'NOUN'), ('of', 'ADP'), ('political', 'ADJ'), ('insiders', 'NOUN'), ('?', '.')], [('Michael', 'NOUN'), ('R.', 'NOUN'), ('Bromwich', 'NOUN'), (',', '.'), ('a', 'DET'), ('member', 'NOUN'), ('since', 'ADP'), ('January', 'NOUN'), ('1987', 'NUM'), ('of', 'ADP'), ('the', 'DET'), ('three-lawyer', 'ADJ'), ('trial', 'NOUN'), ('team', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('prosecution', 'NOUN'), ('of', 'ADP'), ('Oliver', 'NOUN'), ('North', 'NOUN'), (',', '.'), ('became', 'VERB'), ('a', 'DET'), ('partner', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('Washington', 'NOUN'), (',', '.'), ('D.C.', 'NOUN'), (',', '.'), ('office', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('520-lawyer', 'ADJ'), ('firm', 'NOUN'), ('.', '.')], [('Italian', 'ADJ'), ('chemical', 'NOUN'), ('giant', 'NOUN'), ('Montedison', 'NOUN'), ('S.p.A.', 'NOUN'), (',', '.'), ('through', 'ADP'), ('its', 'PRON'), ('Montedison', 'NOUN'), ('Acquisition', 'NOUN'), ('N.V.', 'NOUN'), ('indirect', 'ADJ'), ('unit', 'NOUN'), (',', '.'), ('began', 'VERB'), ('its', 'PRON'), ('$', '.'), ('37-a-share', 'ADJ'), ('*U*', 'X'), ('tender', 'NOUN'), ('offer', 'NOUN'), ('for', 'ADP'), ('all', 'DET'), ('the', 'DET'), ('common', 'ADJ'), ('shares', 'NOUN'), ('outstanding', 'ADJ'), ('of', 'ADP'), ('Erbamont', 'NOUN'), ('N.V.', 'NOUN'), (',', '.'), ('a', 'DET'), ('maker', 'NOUN'), ('of', 'ADP'), ('pharmaceuticals', 'NOUN'), ('incorporated', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('the', 'DET'), ('Netherlands', 'NOUN'), ('.', '.')], [('The', 'DET'), ('teacher', 'NOUN'), ('in', 'ADP'), ('question', 'NOUN'), ('was', 'VERB'), ('Nancy', 'NOUN'), ('Yeargin', 'NOUN'), ('--', '.'), ('considered', 'VERB'), ('by', 'ADP'), ('many', 'ADJ'), ('students', 'NOUN'), ('and', 'CONJ'), ('parents', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('one', 'NUM'), ('of', 'ADP'), ('the', 'DET'), ('best', 'ADJ'), ('at', 'ADP'), ('the', 'DET'), ('school', 'NOUN'), ('.', '.')], [('Some', 'DET'), ('dealers', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('the', 'DET'), ('dollar', 'NOUN'), ('was', 'VERB'), ('pressured', 'ADJ'), ('*-1', 'X'), ('slightly', 'ADV'), ('because', 'ADP'), ('a', 'DET'), ('number', 'NOUN'), ('of', 'ADP'), ('market', 'NOUN'), ('participants', 'NOUN'), ('had', 'VERB'), ('boosted', 'VERB'), ('their', 'PRON'), ('expectations', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('past', 'ADJ'), ('day', 'NOUN'), ('and', 'CONJ'), ('were', 'VERB'), ('looking', 'VERB'), ('for', 'ADP'), ('an', 'DET'), ('index', 'NOUN'), ('above', 'ADP'), ('50', 'NUM'), (',', '.'), ('which', 'DET'), ('*T*-148', 'X'), ('indicates', 'VERB'), ('an', 'DET'), ('expanding', 'VERB'), ('manufacturing', 'NOUN'), ('economy', 'NOUN'), ('.', '.')], [('*', 'X'), ('Do', 'VERB'), (\"n't\", 'ADV'), ('wait', 'VERB'), ('--', '.'), ('a', 'DET'), ('savings', 'NOUN'), ('institution', 'NOUN'), ('needs', 'VERB'), ('your', 'PRON'), ('help', 'NOUN'), ('now', 'ADV'), ('!', '.')], [('The', 'DET'), ('question', 'NOUN'), ('now', 'ADV'), (':', '.'), ('Can', 'VERB'), ('he', 'PRON'), ('act', 'VERB'), ('more', 'ADV'), ('like', 'ADP'), ('hard-charging', 'ADJ'), ('Teddy', 'NOUN'), ('Roosevelt', 'NOUN'), ('?', '.')], [('Reed', 'NOUN'), ('International', 'NOUN'), ('PLC', 'NOUN'), ('said', 'VERB'), ('that', 'ADP'), ('net', 'ADJ'), ('income', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('six', 'NUM'), ('months', 'NOUN'), ('ended', 'VERB'), ('Oct.', 'NOUN'), ('1', 'NUM'), ('slipped', 'VERB'), ('5', 'NUM'), ('%', 'NOUN'), ('to', 'PRT'), ('#', '.'), ('89.7', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('-LRB-', '.'), ('$', '.'), ('141.9', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('-RRB-', '.'), (',', '.'), ('or', 'CONJ'), ('16', 'NUM'), ('pence', 'NOUN'), ('a', 'DET'), ('share', 'NOUN'), (',', '.'), ('from', 'ADP'), ('#', '.'), ('94.8', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('-LRB-', '.'), ('$', '.'), ('149.9', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('-RRB-', '.'), (',', '.'), ('or', 'CONJ'), ('17.3', 'NUM'), ('pence', 'NOUN'), ('a', 'DET'), ('share', 'NOUN'), ('.', '.')], [('Mr.', 'NOUN'), ('Harper', 'NOUN'), ('expressed', 'VERB'), ('confidence', 'NOUN'), ('that', 'ADP'), ('he', 'PRON'), ('and', 'CONJ'), ('Mr.', 'NOUN'), ('Baum', 'NOUN'), ('can', 'VERB'), ('convince', 'VERB'), ('the', 'DET'), ('board', 'NOUN'), ('of', 'ADP'), ('their', 'PRON'), ('worthiness', 'NOUN'), ('*', 'X'), ('to', 'PRT'), ('run', 'VERB'), ('the', 'DET'), ('company', 'NOUN'), ('.', '.')], [('Elsewhere', 'ADV'), (',', '.'), ('share', 'NOUN'), ('prices', 'NOUN'), ('closed', 'VERB'), ('higher', 'ADJ'), ('in', 'ADP'), ('Singapore', 'NOUN'), (',', '.'), ('Taipei', 'NOUN'), ('and', 'CONJ'), ('Wellington', 'NOUN'), (',', '.'), ('were', 'VERB'), ('mixed', 'VERB'), ('in', 'ADP'), ('Hong', 'NOUN'), ('Kong', 'NOUN'), (',', '.'), ('lower', 'ADJ'), ('in', 'ADP'), ('Seoul', 'NOUN'), ('and', 'CONJ'), ('little', 'ADV'), ('changed', 'VERB'), ('in', 'ADP'), ('Sydney', 'NOUN'), ('.', '.')], [('Mexico', 'NOUN'), (',', '.'), ('which', 'DET'), ('*T*-1', 'X'), ('is', 'VERB'), ('normally', 'ADV'), ('a', 'DET'), ('sugar', 'NOUN'), ('exporter', 'NOUN'), (',', '.'), ('has', 'VERB'), ('had', 'VERB'), ('production', 'NOUN'), ('problems', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('past', 'ADJ'), ('two', 'NUM'), ('years', 'NOUN'), (',', '.'), ('analysts', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('*T*-2', 'X'), ('.', '.')], [('The', 'DET'), ('government', 'NOUN'), (\"'s\", 'PRT'), ('borrowing', 'NOUN'), ('authority', 'NOUN'), ('dropped', 'VERB'), ('at', 'ADP'), ('midnight', 'NOUN'), ('Tuesday', 'NOUN'), ('to', 'PRT'), ('$', '.'), ('2.80', 'NUM'), ('trillion', 'NUM'), ('*U*', 'X'), ('from', 'ADP'), ('$', '.'), ('2.87', 'NUM'), ('trillion', 'NUM'), ('*U*', 'X'), ('.', '.')], [('Hadson', 'NOUN'), ('Corp.', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('expects', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('report', 'VERB'), ('a', 'DET'), ('third-quarter', 'NOUN'), ('net', 'ADJ'), ('loss', 'NOUN'), ('of', 'ADP'), ('$', '.'), ('17', 'NUM'), ('million', 'NUM'), ('to', 'PRT'), ('$', '.'), ('19', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('because', 'ADP'), ('of', 'ADP'), ('special', 'ADJ'), ('reserves', 'NOUN'), ('and', 'CONJ'), ('continued', 'VERB'), ('low', 'ADJ'), ('natural-gas', 'NOUN'), ('prices', 'NOUN'), ('.', '.')], [('The', 'DET'), ('city', 'NOUN'), ('had', 'VERB'), ('expected', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('pay', 'VERB'), ('about', 'ADV'), ('11', 'NUM'), ('million', 'NUM'), ('yen', 'NOUN'), ('-LRB-', '.'), ('$', '.'), ('77,000', 'NUM'), ('*U*', 'X'), ('-RRB-', '.'), (',', '.'), ('but', 'CONJ'), ('Fujitsu', 'NOUN'), ('essentially', 'ADV'), ('offered', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('do', 'VERB'), ('it', 'PRON'), ('for', 'ADP'), ('free', 'ADV'), ('.', '.')], [('Deregulation', 'NOUN'), ('has', 'VERB'), ('effectively', 'ADV'), ('removed', 'VERB'), ('all', 'DET'), ('restrictions', 'NOUN'), ('on', 'ADP'), ('what', 'PRON'), ('banks', 'NOUN'), ('can', 'VERB'), ('pay', 'VERB'), ('*T*-201', 'X'), ('for', 'ADP'), ('deposits', 'NOUN'), (',', '.'), ('as', 'ADV'), ('well', 'ADV'), ('as', 'ADP'), ('opened', 'VERB'), ('up', 'PRT'), ('the', 'DET'), ('field', 'NOUN'), ('for', 'ADP'), ('new', 'ADJ'), ('products', 'NOUN'), ('such', 'ADJ'), ('as', 'ADP'), ('high-rate', 'ADJ'), ('CDs', 'NOUN'), ('.', '.')], [('Dodge', 'NOUN'), ('reported', 'VERB'), ('an', 'DET'), ('8', 'NUM'), ('%', 'NOUN'), ('increase', 'NOUN'), ('in', 'ADP'), ('construction', 'NOUN'), ('contracts', 'NOUN'), ('awarded', 'VERB'), ('*', 'X'), ('in', 'ADP'), ('September', 'NOUN'), ('.', '.')], [('``', '.'), ('You', 'PRON'), ('have', 'VERB'), ('...', '.'), ('raised', 'VERB'), ('important', 'ADJ'), ('questions', 'NOUN'), ('which', 'DET'), ('*T*-26', 'X'), ('ought', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('be', 'VERB'), ('answered', 'VERB'), ('*-3', 'X'), (':', '.'), ('What', 'PRON'), ('does', 'VERB'), ('USIA', 'NOUN'), ('say', 'VERB'), ('*T*-27', 'X'), ('about', 'ADP'), ('America', 'NOUN'), ('abroad', 'ADV'), (';', '.'), ('how', 'ADV'), ('do', 'VERB'), ('we', 'PRON'), ('say', 'VERB'), ('it', 'PRON'), ('*T*-4', 'X'), (';', '.'), ('and', 'CONJ'), ('how', 'ADV'), ('can', 'VERB'), ('American', 'ADJ'), ('taxpayers', 'NOUN'), ('get', 'VERB'), ('the', 'DET'), ('answers', 'NOUN'), ('to', 'PRT'), ('these', 'DET'), ('questions', 'NOUN'), ('*T*-5', 'X'), ('?', '.'), (\"''\", '.'), ('a', 'DET'), ('man', 'NOUN'), ('wrote', 'VERB'), ('me', 'PRON'), ('*T*-1', 'X'), ('a', 'DET'), ('couple', 'NOUN'), ('of', 'ADP'), ('years', 'NOUN'), ('ago', 'ADP'), ('.', '.')], [('Savin', 'NOUN'), ('cited', 'VERB'), ('``', '.'), ('a', 'DET'), ('general', 'ADJ'), ('softening', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('demand', 'NOUN'), ('for', 'ADP'), ('office', 'NOUN'), ('products', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('market', 'NOUN'), ('segments', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('Savin', 'NOUN'), ('competes', 'VERB'), ('*T*-1', 'X'), ('.', '.')], [('The', 'DET'), ('National', 'NOUN'), ('Association', 'NOUN'), ('of', 'ADP'), ('Manufacturers', 'NOUN'), ('settled', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('Hoosier', 'NOUN'), ('capital', 'NOUN'), ('of', 'ADP'), ('Indianapolis', 'NOUN'), ('for', 'ADP'), ('its', 'PRON'), ('fall', 'NOUN'), ('board', 'NOUN'), ('meeting', 'NOUN'), ('.', '.')], [('And', 'CONJ'), ('several', 'ADJ'), ('new', 'ADJ'), ('funds', 'NOUN'), ('that', 'DET'), ('*T*-44', 'X'), ('are', 'VERB'), (\"n't\", 'ADV'), ('even', 'ADV'), ('fully', 'ADV'), ('invested', 'VERB'), ('yet', 'ADV'), ('have', 'VERB'), ('jumped', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('trade', 'VERB'), ('at', 'ADP'), ('big', 'ADJ'), ('premiums', 'NOUN'), ('.', '.')], [('During', 'ADP'), ('the', 'DET'), ('coming', 'VERB'), ('weeks', 'NOUN'), (',', '.'), ('President', 'NOUN'), ('Bush', 'NOUN'), ('must', 'VERB'), ('decide', 'VERB'), ('whether', 'ADP'), ('*', 'X'), ('to', 'PRT'), ('veto', 'VERB'), ('the', 'DET'), ('bills', 'NOUN'), ('containing', 'VERB'), ('them', 'PRON'), ('--', '.'), ('or', 'CONJ'), (',', '.'), ('alternatively', 'ADV'), (',', '.'), ('*', 'X'), ('to', 'PRT'), ('sign', 'VERB'), ('these', 'DET'), ('bills', 'NOUN'), ('into', 'ADP'), ('law', 'NOUN'), ('with', 'ADP'), ('a', 'DET'), ('statement', 'NOUN'), ('declaring', 'VERB'), ('their', 'PRON'), ('intrusions', 'NOUN'), ('on', 'ADP'), ('executive', 'ADJ'), ('power', 'NOUN'), ('to', 'PRT'), ('be', 'VERB'), ('in', 'ADP'), ('violation', 'NOUN'), ('of', 'ADP'), ('Article', 'NOUN'), ('II', 'NOUN'), (',', '.'), ('and', 'CONJ'), ('thus', 'ADV'), ('void', 'ADJ'), ('and', 'CONJ'), ('severable', 'ADJ'), ('.', '.')], [('Medical', 'ADJ'), ('researchers', 'NOUN'), ('believe', 'VERB'), ('0', 'X'), ('the', 'DET'), ('transplantation', 'NOUN'), ('of', 'ADP'), ('small', 'ADJ'), ('amounts', 'NOUN'), ('of', 'ADP'), ('fetal', 'ADJ'), ('tissue', 'NOUN'), ('into', 'ADP'), ('humans', 'NOUN'), ('could', 'VERB'), ('help', 'VERB'), ('*', 'X'), ('treat', 'VERB'), ('juvenile', 'ADJ'), ('diabetes', 'NOUN'), ('and', 'CONJ'), ('such', 'ADJ'), ('degenerative', 'ADJ'), ('diseases', 'NOUN'), ('as', 'ADP'), ('Alzheimer', 'NOUN'), (\"'s\", 'PRT'), (',', '.'), ('Parkinson', 'NOUN'), (\"'s\", 'PRT'), ('and', 'CONJ'), ('Huntington', 'NOUN'), (\"'s\", 'PRT'), ('.', '.')], [('The', 'DET'), ('banks', 'NOUN'), ('have', 'VERB'), ('28', 'NUM'), ('days', 'NOUN'), ('0', 'X'), ('*', 'X'), ('to', 'PRT'), ('file', 'VERB'), ('an', 'DET'), ('appeal', 'NOUN'), ('against', 'ADP'), ('the', 'DET'), ('ruling', 'NOUN'), ('*T*-2', 'X'), ('and', 'CONJ'), ('are', 'VERB'), ('expected', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('do', 'VERB'), ('so', 'ADV'), ('shortly', 'ADV'), ('.', '.')], [('As', 'ADP'), ('a', 'DET'), ('result', 'NOUN'), (',', '.'), ('the', 'DET'), ('company', 'NOUN'), ('said', 'VERB'), ('0', 'X'), ('it', 'PRON'), ('decided', 'VERB'), ('*-1', 'X'), ('to', 'PRT'), ('phase', 'VERB'), ('out', 'PRT'), ('its', 'PRON'), ('oldest', 'ADJ'), ('capacity', 'NOUN'), ('and', 'CONJ'), ('``', '.'), ('make', 'VERB'), ('appropriate', 'ADJ'), ('reductions', 'NOUN'), (\"''\", '.'), ('in', 'ADP'), ('operating', 'NOUN'), ('expenses', 'NOUN'), ('.', '.')], [('Giant', 'NOUN'), ('Group', 'NOUN'), ('is', 'VERB'), ('led', 'VERB'), ('*-96', 'X'), ('by', 'ADP'), ('three', 'NUM'), ('Rally', 'NOUN'), (\"'s\", 'PRT'), ('directors', 'NOUN'), (',', '.'), ('Burt', 'NOUN'), ('Sugarman', 'NOUN'), (',', '.'), ('James', 'NOUN'), ('M.', 'NOUN'), ('Trotter', 'NOUN'), ('III', 'NOUN'), ('and', 'CONJ'), ('William', 'NOUN'), ('E.', 'NOUN'), ('Trotter', 'NOUN'), ('II', 'NOUN'), (',', '.'), ('who', 'PRON'), ('last', 'ADJ'), ('month', 'NOUN'), ('*T*-1', 'X'), ('indicated', 'VERB'), ('0', 'X'), ('they', 'PRON'), ('hold', 'VERB'), ('a', 'DET'), ('42.5', 'NUM'), ('%', 'NOUN'), ('stake', 'NOUN'), ('in', 'ADP'), ('Rally', 'NOUN'), (\"'s\", 'PRT'), ('and', 'CONJ'), ('plan', 'VERB'), ('*-2', 'X'), ('to', 'PRT'), ('seek', 'VERB'), ('a', 'DET'), ('majority', 'NOUN'), ('of', 'ADP'), ('seats', 'NOUN'), ('on', 'ADP'), ('Rally', 'NOUN'), (\"'s\", 'PRT'), ('nine-member', 'ADJ'), ('board', 'NOUN'), ('.', '.')], [('IBM', 'NOUN'), (',', '.'), ('the', 'DET'), ('giant', 'ADJ'), ('computer', 'NOUN'), ('maker', 'NOUN'), (',', '.'), ('offered', 'VERB'), ('$', '.'), ('750', 'NUM'), ('million', 'NUM'), ('*U*', 'X'), ('of', 'ADP'), ('non-callable', 'ADJ'), ('30-year', 'ADJ'), ('debentures', 'NOUN'), ('priced', 'VERB'), ('*', 'X'), ('*-1', 'X'), ('to', 'PRT'), ('yield', 'VERB'), ('8.47', 'NUM'), ('%', 'NOUN'), (',', '.'), ('or', 'CONJ'), ('about', 'ADP'), ('1\\\\/2', 'NUM'), ('percentage', 'NOUN'), ('point', 'NOUN'), ('higher', 'ADJ'), ('than', 'ADP'), ('the', 'DET'), ('yield', 'NOUN'), ('on', 'ADP'), ('30-year', 'ADJ'), ('Treasury', 'NOUN'), ('bonds', 'NOUN'), ('.', '.')], [('Several', 'ADJ'), ('Fed', 'NOUN'), ('governors', 'NOUN'), ('in', 'ADP'), ('Washington', 'NOUN'), ('have', 'VERB'), ('been', 'VERB'), ('pushing', 'VERB'), ('for', 'ADP'), ('easier', 'ADJ'), ('credit', 'NOUN'), (';', '.'), ('but', 'CONJ'), ('many', 'ADJ'), ('of', 'ADP'), ('the', 'DET'), ('regional', 'ADJ'), ('Fed', 'NOUN'), ('presidents', 'NOUN'), ('have', 'VERB'), ('been', 'VERB'), ('resisting', 'VERB'), ('such', 'ADJ'), ('a', 'DET'), ('move', 'NOUN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(nltk_data,test_size=0.05)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95621"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting list of tagged words\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "len(train_tagged_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In',\n",
       " 'composite',\n",
       " 'trading',\n",
       " 'on',\n",
       " 'the',\n",
       " 'New',\n",
       " 'York',\n",
       " 'Stock',\n",
       " 'Exchange',\n",
       " ',']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokens \n",
    "tokens = [pair[0] for pair in train_tagged_words]\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12076\n"
     ]
    }
   ],
   "source": [
    "# vocabulary\n",
    "V = set(tokens)\n",
    "print(len(V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of tags\n",
    "T = set([pair[1] for pair in train_tagged_words])\n",
    "len(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ADV', 'ADJ', '.', 'ADP', 'CONJ', 'X', 'NUM', 'PRON', 'DET', 'NOUN', 'VERB', 'PRT'}\n"
     ]
    }
   ],
   "source": [
    "print(T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the vanilla Viterbi based POS tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing P(w/t) and storing in T x V matrix\n",
    "t = len(T)\n",
    "v = len(V)\n",
    "w_given_t = np.zeros((t, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute word given tag: Emission Probability\n",
    "def word_given_tag(word, tag, train_bag = train_tagged_words):\n",
    "    tag_list = [pair for pair in train_bag if pair[1]==tag]\n",
    "    count_tag = len(tag_list)\n",
    "    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n",
    "    count_w_given_tag = len(w_given_tag_list)\n",
    "    \n",
    "    return (count_w_given_tag, count_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute tag given tag: tag2(t2) given tag1 (t1), i.e. Transition Probability\n",
    "\n",
    "def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n",
    "    tags = [pair[1] for pair in train_bag]\n",
    "    count_t1 = len([t for t in tags if t==t1])\n",
    "    count_t2_t1 = 0\n",
    "    for index in range(len(tags)-1):\n",
    "        if tags[index]==t1 and tags[index+1] == t2:\n",
    "            count_t2_t1 += 1\n",
    "    return (count_t2_t1, count_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating t x t transition matrix of tags\n",
    "# each column is t2, each row is t1\n",
    "# thus M(i, j) represents P(tj given ti)\n",
    "tags_matrix = np.zeros((len(T), len(T)), dtype='float32')\n",
    "for i, t1 in enumerate(list(T)):\n",
    "    for j, t2 in enumerate(list(T)): \n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the matrix to a df for better readability\n",
    "tags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADV     0.053297\n",
       "ADJ     0.043786\n",
       ".       0.093943\n",
       "ADP     0.090624\n",
       "CONJ    0.058232\n",
       "X       0.027008\n",
       "NUM     0.080126\n",
       "PRON    0.065590\n",
       "DET     0.173800\n",
       "NOUN    0.221893\n",
       "VERB    0.089098\n",
       "PRT     0.002512\n",
       "Name: ., dtype: float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_df.loc['.', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap of tags matrix\n",
    "# T(i, j) means P(tag j given tag i)\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequent tags\n",
    "# filter the df to get P(t2, t1) > 0.5\n",
    "tags_frequent = tags_df[tags_df>0.5]\n",
    "plt.figure(figsize=(18, 12))\n",
    "sns.heatmap(tags_frequent)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Viterbi Heuristic\n",
    "def Viterbi(words, train_bag = train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "    \n",
    "    for key, word in enumerate(words):\n",
    "        #initialise list of probability column for a given observation\n",
    "        p = [] \n",
    "        for tag in T:\n",
    "            if key == 0:\n",
    "                transition_p = tags_df.loc['.', tag]\n",
    "            else:\n",
    "                transition_p = tags_df.loc[state[-1], tag]\n",
    "                \n",
    "            # compute emission and state probabilities\n",
    "            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n",
    "            state_probability = emission_p * transition_p    \n",
    "            p.append(state_probability)\n",
    "            \n",
    "        pmax = max(p)\n",
    "        # getting state for which probability is maximum\n",
    "        state_max = T[p.index(pmax)] \n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Android is a mobile operating system developed by Google.', 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.', \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\", 'Twitter is an online news and social networking service on which users post and interact with messages known as tweets.', 'Before entering politics, Donald Trump was a domineering businessman and a television personality.', 'The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.', 'This is the first World Cup to be held in Eastern Europe and the 11th time that it has been held in Europe.', 'Show me the cheapest round trips from Dallas to Atlanta\\nI would like to see flights from Denver to Philadelphia.', 'Show me the price of the flights leaving Atlanta at about 3 in the afternoon and arriving in San Francisco.', 'NASA invited social media users to experience the launch of ICESAT-2 Satellite.']\n"
     ]
    }
   ],
   "source": [
    "with open('Test_sentences_1.txt','r',encoding='utf8') as f:\n",
    "    test_set = f.read()\n",
    "# list of untagged words\n",
    "sent_text = nltk.sent_tokenize(str(test_set))\n",
    "print(sent_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-49-2f3d58eec489>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtokenized_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m#print(tokenized_text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtagged\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mViterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mtagged_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-d5d285c53e57>\u001b[0m in \u001b[0;36mViterbi\u001b[1;34m(words, train_bag)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mViterbi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_bag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_tagged_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_bag\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# now loop over each sentence and tokenize it separately\n",
    "start = time.time()\n",
    "tagged_data = []\n",
    "for sentence in sent_text:\n",
    "    tokenized_text = nltk.word_tokenize(sentence)\n",
    "    #print(tokenized_text)\n",
    "    tagged = Viterbi(tokenized_text)\n",
    "    tagged_data.append(tagged)\n",
    "    print(tagged)\n",
    "end = time.time()\n",
    "difference = end-start\n",
    "print(\"Time taken in seconds: \", difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solve the problem of unknown words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "nltk_word =[]\n",
    "for i in range(len(nltk_data)):\n",
    "    a.append([pair[0] for pair in nltk_data[i]])\n",
    "for list in a:\n",
    "    for word in list:\n",
    "        nltk_word.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "tagged_word =[]\n",
    "for i in range(len(tagged_data)):\n",
    "    b.append([pair[0] for pair in tagged_data[i]])\n",
    "for list in b:\n",
    "    for word in list:\n",
    "        tagged_word.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the unknown keywords\n",
    "unknownwords = set(tagged_word).union(set(nltk_word))  - set(tagged_word).intersection(set(nltk_word)) - set(nltk_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['domineering', 'Google', 'arriving', 'invited', 'interact', 'Cup', 'FIFA', 'online', 'Satellite', 'NASA', 'trips', 'OS', '21st', 'Android', 'ICESAT-2', 'smartphones', '2011', 'messages', '2018', '2015', 'firehose', 'worldwide', 'Twitter', 'personality', '2013', 'contested', 'tweets', 'tournament']\n"
     ]
    }
   ],
   "source": [
    "unknownwords = [ k for k in unknownwords ]\n",
    "print(unknownwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Android , ADV\n",
      "Google , ADV\n",
      "Android , ADV\n",
      "OS , ADV\n",
      "worldwide , ADV\n",
      "smartphones , ADV\n",
      "2011 , ADV\n",
      "2013 , ADV\n",
      "Google , ADV\n",
      "Twitter , ADV\n",
      "2015 , ADV\n",
      "Google , ADV\n",
      "Twitter , ADV\n",
      "firehose , ADV\n",
      "Twitter , ADV\n",
      "online , ADV\n",
      "interact , ADV\n",
      "messages , ADV\n",
      "tweets , ADV\n",
      "domineering , ADV\n",
      "personality , ADV\n",
      "2018 , ADV\n",
      "FIFA , ADV\n",
      "Cup , ADV\n",
      "21st , ADV\n",
      "FIFA , ADV\n",
      "Cup , ADV\n",
      "tournament , ADV\n",
      "contested , ADV\n",
      "Cup , ADV\n",
      "trips , ADV\n",
      "arriving , ADV\n",
      "NASA , ADV\n",
      "invited , ADV\n",
      "ICESAT-2 , ADV\n",
      "Satellite , ADV\n"
     ]
    }
   ],
   "source": [
    "c = []\n",
    "tagged =[]\n",
    "for i in range(len(tagged_data)):\n",
    "    c.append([pair for pair in tagged_data[i]])\n",
    "for list in c:\n",
    "   for word in list:\n",
    "       tagged.append(word)\n",
    "for tag in tagged:\n",
    "    for word in unknownwords:\n",
    "        if word in tag:\n",
    "            print(word,',',tag[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Assign NOUN if capitalized\n",
    "'''\n",
    "def apply_capitalization_assignment(word=None, pos=-1):\n",
    "    if len(word.pos_tags) == 0:\n",
    "        if word.orig_text[0].isupper():\n",
    "            word.pos_tags = ['NOUN']\n",
    "\n",
    "    if pos > 0:\n",
    "        if word.orig_text[0].isupper():\n",
    "            word.pos_tags = ['NOUN']\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Assign possible tags helper function: Dictionary Search\n",
    "'''\n",
    "from cebdict import dictionary\n",
    "def dictionary_search(word=None):\n",
    "    if word.is_entry:\n",
    "        # pos_tags = search_term(entries=stemmer.entries, term=word.root)\n",
    "        pos_tags = dictionary.search(word.root)\n",
    "        if pos_tags:\n",
    "            word.pos_tags = pos_tags\n",
    "            word.root_tags = word.pos_tags\n",
    "\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "POS Tag Assignment\n",
    "Assigns all possible POS tags per token\n",
    "'''\n",
    "from cebstemmer import stemmer\n",
    "import string\n",
    "def assign_pos_tags(tokens=[]):\n",
    "    words = []\n",
    "    for idx, token in enumerate(tokens):\n",
    "        #stem = stemmer.stem_word(word=token, as_object=True)\n",
    "        #word = dictionary_search(word=token)\n",
    "        #word = function_words_search(word=stem)\n",
    "        #word = apply_lexical_rules_assignment(word=stem)\n",
    "        word = apply_capitalization_assignment(word=token, pos=idx)\n",
    "\n",
    "        if len(word.pos_tags) == 0:\n",
    "            if stem.text.isdigit():\n",
    "                # Assign num if the word is a numerical value\n",
    "                word.pos_tags = ['NUM']\n",
    "            elif stem.text in string.punctuation:\n",
    "                word.pos_tags = ['SYM']\n",
    "            else:\n",
    "                word.pos_tags = ['OTH']\n",
    "\n",
    "        words.append(word)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Given a Cebuano sentence, it will tag all words with its corresponding POS tags\n",
    "'''\n",
    "def tag_sentence(tokens):\n",
    "    #tokens = tokenize(text=text)\n",
    "    words = assign_pos_tags(tokens=tokens)\n",
    "    \n",
    "    sentence = []\n",
    "    for word in words:\n",
    "        sentence.append((word.orig_text.encode('utf-8'), word.pos_tags[0]))\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'pos_tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-7f14dc5faec9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtag_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munknownwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-c9dcc03538b3>\u001b[0m in \u001b[0;36mtag_sentence\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtag_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#tokens = tokenize(text=text)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0massign_pos_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-61-5b479edcd818>\u001b[0m in \u001b[0;36massign_pos_tags\u001b[1;34m(tokens)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m#word = function_words_search(word=stem)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;31m#word = apply_lexical_rules_assignment(word=stem)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mword\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_capitalization_assignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-dce58c9365e4>\u001b[0m in \u001b[0;36mapply_capitalization_assignment\u001b[1;34m(word, pos)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_capitalization_assignment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tags\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_text\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mword\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'NOUN'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'pos_tags'"
     ]
    }
   ],
   "source": [
    "tag_sentence(unknownwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating tagging accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List down cases which were incorrectly tagged by original POS tagger and got corrected by your modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
